{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ê²°ì¸¡ì¹˜ ì²˜ë¦¬ë²• 3ê°€ì§€\n",
    "1. ê²°ì¸¡í–‰ ì œê±°\n",
    "2. ê²°ì¸¡ê°’ ëŒ€ì²´\n",
    "3. ê²°ì¸¡ê°’ ëŒ€ì²´ ë° ëŒ€ì²´ìœ ë¬´ì— ëŒ€í•´ ê¸°ì…\n",
    "\n",
    "2ë²ˆê³¼ 3ë²ˆì—ì„œ \"ëŒ€ì²´\"ì‹œì— SimpleImputerë¥¼ í™œìš©\n",
    "Kaggle: SimpleImputerëŠ” í‰ê· ê°’ìœ¼ë¡œ ê°’ì„ ëŒ€ì²´. ì‚¬ëŒë“¤ì€ ë³´í†µ ê²°ì¸¡ê°’ì„ complexí•œ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´í•˜ê¸° ìœ„í•´\n",
    "ë‹¤ì–‘í•œ ë°©ë²•ì„ í™œìš© (ex. regression imputation). ê·¸ëŸ¬ë‚˜ ì´ëŠ” ë³µì¡í•œ MLëª¨ë¸ì´ í™œìš©ëœë‹¤ë©´,\n",
    "ì´ì— ëŒ€í•œ ì´ì ì€ ê±°ì˜ ì—†ì–´ì§„ë‹¤ê³  ë³´ë©´ ëœë‹¤.\n",
    "\n",
    "==============================================================================================================================\n",
    "\n",
    "ê¶ê¸ˆ: fit_transformê³¼ transformì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€?\n",
    "\n",
    "fit_transform() ë©”ì†Œë“œëŠ” ë§ ê·¸ëŒ€ë¡œ fit()í•œ ë‹¤ìŒì— transform() í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n",
    "ì—¬ê¸°ì„œ fit()ì´ë€ ì •ê·œí™” ì¦‰, í†µê³„ì—ì„œ ì •ê·œë¶„í¬ë¥¼ ë§Œë“¤ê²Œ í•˜ê¸° ìœ„í•´ì„œ ğ‘¥ ê°’ì—ì„œ í‰ê· ì„ ë¹¼ê³  \n",
    "ê·¸ ê°’ì„ ë‹¤ì‹œ í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆ„ì–´ì£¼ëŠ” ì‘ì—…ì„ í•˜ëŠ”ë° \n",
    "ì´ ì‘ì—…ì„ í•˜ê¸° ìœ„í•´ í‰ê·  ğœ‡ê³¼  í‘œì¤€í¸ì°¨ ğœë¥¼ ê³„ì‚°í•˜ëŠ” ì‘ì—…ì´ fit() ì´ê³ , transform()ì€ ì •ê·œí™” ì‘ì—…ì„ í•´ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤. \n",
    "(ğ‘¥-ğœ‡)/ğœ ==> ìƒˆë¡œìš´ ğ‘¥â€² ìƒê¸°ëŠ” ê²ƒì´ì£ \n",
    "\n",
    "íŠ¸ë ˆì´ë‹ ë°ì´í„°ì— ëŒ€í•´ì„œ fit ì‘ì—…ê³¼ transform ì‘ì—…ì„ ì ìš©í•´ì£¼ëŠ” ê²ƒì´ fit_transformì´ê³  \n",
    "ì—¬ê¸°ì„œ ê³„ì‚°ëœ í‰ê·  ğœ‡ê³¼  í‘œì¤€í¸ì°¨ ğœë¥¼ ë™ì¼í•˜ê²Œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•´ì„œ ì •ê·œí™” ì‘ì—…ì„ í•´ì£¼ëŠ” ê²½ìš°ëŠ” transform()ë§Œ ì ìš©í•©ë‹ˆë‹¤.  \n",
    "í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ë„ íŠ¸ë ˆì´ë‹ ë°ì´í„°ì— ì ìš©ë˜ì—ˆë˜ ë™ì¼í•œ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ì„œ \n",
    "ì´ì „ì— fit_transform()ì—ì„œ ê³„ì‚°ëœ ê°’ë“¤ì´ ì €ì¥ëœ ìƒíƒœì—ì„œ transform()ì— ì ìš©ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "ì•„ë˜ ì¶œì²˜ë¥¼ ë”°ë¼ê°€ ë³´ì‹œë©´ fit_transformì˜ íŒŒë¼ë¯¸í„°ë“¤ì„ ìì„¸íˆ ì‚´í´ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • ì—´ì—ì„œ ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ì„ ì œê±°í•  ë•Œ subset ì¸ìë¥¼ í™œìš©\n",
    "X_full.dropna(axis=0, subset=['LotFrontage'], inplace=True)\n",
    "\n",
    "# ìë£Œí˜•ì´ objectê°€ ì•„ë‹Œ ê²ƒë§Œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "\n",
    "# SimpleImputerì— í‰ê·  ëŒ€ì‹  ì¤‘ê°„ê°’ìœ¼ë¡œ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ë°©ë²•\n",
    "final_imputer = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ì—´ ë³„ ê²°ì¸¡ì¹˜ì˜ ê°œìˆ˜ë¥¼ ë³´ê³  í•´ë‹¹ ì—´ì„ ì œê±°í•´ì•¼í•˜ëŠ”ê°€? ìƒê°\n",
    "--> ì—´ ìì²´ë¥¼ ì œê±°í•˜ëŠ” ê²ƒì€ ê·€ì¤‘í•œ ë°ì´í„°ë¥¼ ì œê±°í•˜ëŠ” ê²ƒì´ë‹¤. í•˜ì§€ë§Œ, ê²°ì¸¡ì¹˜ì˜ ê°œìˆ˜ê°€ ì—´ ì „ì²´ì˜ ê°œìˆ˜ì˜ 20%ë¯¸ë§Œì´ë¼ë©´ ì œê±°í•˜ì§€ë§ì.\n",
    "ì˜¤íˆë ¤ ì´ëŸ´ë• ëŒ€ì²´í•˜ëŠ” ê²ƒì´ ë°”ëŒì§ í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "ë°ì´í„° ì„¸íŠ¸ì— ê²°ì¸¡ê°’ì´ ë„ˆë¬´ ì ê¸° ë•Œë¬¸ì— ì—´ì„ ì™„ì „íˆ ì‚­ì œí•˜ëŠ” ê²ƒë³´ë‹¤ ê·€ì±…ì„±ì´ ë” ì˜ ìˆ˜í–‰ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒí•œë‹¤. \n",
    "ê·¸ëŸ¬ë‚˜ ì—´ì„ ë–¨ì–´ëœ¨ë¦¬ëŠ” ê²ƒì´ ì•½ê°„ ë” ë‚«ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "ì´ëŠ” ë°ì´í„° ì„¸íŠ¸ì˜ ë…¸ì´ì¦ˆì— ë¶€ë¶„ì ìœ¼ë¡œ ê¸°ì¸í•  ìˆ˜ ìˆì§€ë§Œ, \n",
    "ë˜ ë‹¤ë¥¸ ì ì¬ì ì¸ ì„¤ëª…ì€ ê·€ì±… ë°©ë²•ì´ ì´ ë°ì´í„° ì„¸íŠ¸ì™€ í¬ê²Œ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì´ë‹¤.\n",
    "\n",
    "ì¦‰, í‰ê·  ê°’ì„ ì±„ìš°ëŠ” ëŒ€ì‹  ëª¨ë“  ê²°ì¸¡ê°’ì„ 0 ê°’ìœ¼ë¡œ ì„¤ì •í•˜ê±°ë‚˜, \n",
    "ê°€ì¥ ìì£¼ ë°œìƒí•˜ëŠ” ê°’ì„ ì±„ìš°ê±°ë‚˜, ë‹¤ë¥¸ ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” í•©ë¦¬ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê° ì—´ì„ ë”°ë¼ ì¤‘ìœ„ìˆ˜ ê°’ì„ ì±„ìš°ëŠ” ê²ƒì´ ë” ì˜ë¯¸ê°€ ìˆìŠµë‹ˆê¹Œ? \n",
    "ì•„ë‹ˆë©´ ê° ì—´ì„ ë”°ë¼ ìµœì†Œê°’ì„ ì±„ì›Œ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì„ê¹Œìš”? \n",
    "ì´ ê²½ìš°ì— ë¬´ì—‡ì´ ìµœì„ ì¸ì§€ í™•ì‹¤í•˜ì§€ ì•Šì§€ë§Œ, ì•„ë§ˆë„ ìš°ë¦¬ëŠ” ì¦‰ì‹œ ëª‡ ê°€ì§€ ì˜µì…˜ì„ ë°°ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "    ì˜ˆë¥¼ ë“¤ì–´, ì´ ì—´ì˜ ê²°ì¸¡ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ë”ì°í•œ ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ CITYì²˜ëŸ¼ ê²½ê¸°, ê°•ì›ì„ valueë¡œ ê°–ëŠ” ë³€ìˆ˜ì˜ ê²½ìš° ì²˜ë¦¬ë°©ë²•\n",
    "1. Drop\n",
    "2. ìˆ«ìì— mapping\n",
    " - sklearnì˜ labelencoderë¥¼ ì“°ë©´ í¸ë¦¬ --> ê·¸ëŸ¬ë‚˜, ê° ê°’ì— ë¬´ì‘ìœ„ ìˆ«ìë¥¼ ëŒ€ì‘\n",
    " - ì´ë ‡ê²Œ ë˜ë©´ í¬ê¸°ìš”ì†Œë¥¼ ë°˜ì˜í•˜ê¸° í˜ë“¤ë“¯ ì‹¶ì€ë°?\n",
    "3. one-hot-encoding\n",
    " - sklearnì˜ OneHotEncoderë¥¼ ì“´ë‹¤.\n",
    " - íŒŒë¼ë¯¸í„° ì„¤ëª…\n",
    "  -- handle_unknown='ignore': trainì— ì›-í•«-ì¸ì½”ë”© í›„, validation dataì—ì„œ ì—†ëŠ” ì¹´í…Œê³ ë¦¬ ë°œê²¬ì‹œ ì˜¤ë¥˜ë°œìƒx \n",
    "  -- sparse=False: ë°˜í™˜ê°ì²´ê°€ numpy\n",
    "  \n",
    "*** labelencoderë‚˜ onehotencoder í™œìš© ì „ì— ê¼­ trainê³¼ valid dataì˜ êµ¬ì„±ì´ ë§ëŠ”ì§€ í™•ì¸í•´!\n",
    "*** onehotencodingì€ ë³€ìˆ˜ì˜ valueìˆ˜ê°€ ì ì„ë•Œ ë§ì´ í™œìš©ë˜ê³ , nominalì´ì§€ë§Œ valueì˜ ìˆ˜ê°€ ë§ë‹¤ë©´ ì•„ì‹¸ë¦¬ ì œê±°í•˜ê±°ë‚˜ labelencoding\n",
    "'''\n",
    "\n",
    "ê¶ê¸ˆ! : handle_unknown='ignore'ì„ ì‹¤ì‹œì‹œ, ì—†ëŠ” ê°’ì€ ê·¸ëƒ¥ ì œì™¸ë˜ëŠ” ê²ƒì¸ì§€?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapê³¼ lambdaí•¨ìˆ˜\n",
    "\n",
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols)) #mapê³¼ lambdaëŠ” í•­ìƒ ê°™ì´ ë‹¤ë‹˜. map(lambda ì¸ì: í•¨ìˆ˜ì‹, ë„£ì„ ì¸ì)\n",
    "d = dict(zip(object_cols, object_nunique)) # [(, ), (, ), (, ) ]ë“±ì˜ í˜•íƒœë¡œ ë‹¤ìˆ˜ ë“¤ì–´ê°€ë©°, dictí•¨ìˆ˜ë¥¼ ê±°ì¹¨ìœ¼ë¡œì¨ dictionaryë¡œ ë³€í™˜\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ êµ¬ì„±ë²•1\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('../input/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ êµ¬ì„±ë²•2\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = clf.predict(X_valid)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ë°ì´í„°ê°€ ì ì„ë•Œ, CVë¥¼ ì“°ì. ë°ì´í„°ê°€ ì ì€ë°, Validation setê¹Œì§€ ë¹¼ë‚´ë ¤ë¨¼ í›ˆë ¨dataê°€ ì ì–´ì§€ê¸° ë–„ë¬¸.\n",
    "ë°ì´í„°ê°€ í¬ë©´, single validationì„ ì‹¤ì‹œí•˜ì! (í¬ë©´ ì‹œê°„ì´ ë§ì´ ê±¸ë¦¬ì–ì•„!)\n",
    "Piplineì„ í™œìš©í•˜ë©´ CVê°€ í›¨ì”¬ ì‰¬ì›€!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n",
    "                              ('model', RandomForestRegressor(n_estimators=50,\n",
    "                                                              random_state=0))\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"MAE scores:\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average MAE score (across experiments):\")\n",
    "print(scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
